# Severe Mental Illness and Social issues in London

```{r warning=FALSE, message=FALSE}
library(sf)
library(tidyverse)
library(tmap)
library(janitor)
library(here)
library(broom)
library(car)
library(cowplot)
library(corrr)
library(sp)
library(spdep)
library(spgwr)
library(spatialreg)
library(readxl)
```

## Project Scope

**Research question**

-   Is there any relationship between CMD(Common Mental Disorders) and social issues such as population density, deprivation, and household composition in London?

**References**
From Dr. Jay's presentation
- Likelihood of CMDs is higher in people living alone, with poor physical health and not in work (APMS 2014).
- Strong association with area deprivation

**Hypothesis**

-   Higher population density and deprivation rate lead to a higher number of SMI patient in London
-   Single household lead the higher number of CMD patient

**Data**

- 

**Analysis**

-   Map SAMHI index across London LSOA
-   Load population density, deprivation, and ethnicity data

- Mental health index echibit Spatial autocorrelation
-   Conduct multiple linear regression with SMI index as the dependent variable and selected social issues as independent variables
-   Experiment with the spatial lag and spatial error models, comparing their results
-   Run geographically weighted regression (GWR) to see if there is local variation that is not captured by the global model

**Assumptions**


## Data

[Statistical GIS Boundary Files for London](https://data.london.gov.uk/dataset/statistical-gis-boundary-files-london)

-   This data contains various GIS boundary files for London at different spatial aggregation units, including Lower Super Output Area (LSOA), Middle Super Output Area (MSOA), Wards and Boroughs.
-   For this analysis, we will use LSOA data so that the spatial units correspond with the data available on SMI index
-   Transform the data to a projected coordinate reference system, the British National Grid.

[SMI index data at LSOA level 2011](https://pldr.org/dataset/2noyv/small-area-mental-health-index-samhi)

-   The SAMHI is a composite annual measure of population mental health for each Lower Super Output Area (LSOA) in England. The SAMHI combines data on mental health from multiple sources (NHS-Mental health related hospital attendances, Prescribing data -- Antidepressants, QOF - depression, and DWP - Incapacity benefit and Employment support allowance for mental illness) into a single index.
-   The SAMHI index contains 2011-2019 data based on LSOA level in all England
- We use SAMHI_dec 

[Population Density Data 2011 Census](_)

-   This data based on the 2011 Census and we choose LSOA
-   We will choose these columns:
    -   geography_code
    -   area_population_density_density_number_of_persons_per_hectare_measures_value

### LSOA boundary data

```{r LSOA boundary}
lsoa <- st_read(here::here("data", "statistical-gis-boundaries-london","ESRI", "LSOA_2011_London_gen_MHW.shp")) %>%
  st_transform(., 27700)

summary(lsoa)

qtm(lsoa)
```

There are 4835 LSOA in London in 2011.

### SMI index data

```{r SAMHI index}
samhi_index <- read_csv(here::here("data","samhi_21_01_v4.00_2011_2019_LSOA_tall.csv"),locale=locale(encoding = "latin1")) %>%
  clean_names()
```

```{r}
# filter 2019 and SAMHI index column
samhi_2011 <- samhi_index %>%
  select(lsoa11,year,samhi_dec)%>%
  filter(str_detect(year, "2011"))

summary(samhi_2011)
```

```{r}
# join SAMHI index to LSOA boundary
samhi <- lsoa %>%
  left_join(.,
            samhi_2011, 
            by = c("LSOA11CD" = "lsoa11"))

Datatypelist <- samhi %>% 
  st_drop_geometry() %>%
  summarise_all(class) %>%
  pivot_longer(everything(), 
               names_to="All_variables", 
               values_to="Variable_class")

# plot SAMHI index (deciles)
#qtm(samhi, 
#    fill = "samhi_dec",
#    fill.palette = "Blues")
```

### Population Density Data

```{r pop_density}
pd <- read_csv(here::here("data","population_density.csv"),locale=locale(encoding = "latin1"))%>%
  clean_names()
```

```{r}
# filter 2011 and population density column
pd_2011 <- pd %>%
  select(geography_code, area_population_density_density_number_of_persons_per_hectare_measures_value)

summary(pd_2011)
```

### Socio-economic

```{r deprivation}
depriv <- read_excel(here::here("data","lsoa-data.xls"))%>%
  clean_names()

head(depriv)
```

```{r}
# filter 2011 and population density column
depriv_2011 <- depriv %>%
  select(.,codes, unemployment_rate,median_annual_household_income_estimate)%>%
  rename(annual_income=median_annual_household_income_estimate)

summary(depriv_2011)
```

### Household
```{r}
hc <- read_csv(here::here("data","household.csv"),locale=locale(encoding = "latin1")) %>%
  clean_names()
```

```{r}
hc <- read_csv(here::here("data","household.csv"),locale=locale(encoding = "latin1")) %>%
  clean_names()
```

```{r}
hc_2011 <- hc%>%
  mutate(single_hc=household_composition_one_person_household_measures_value/household_composition_all_categories_household_composition_measures_value)%>%
  select(geography_code, single_hc)
```

```{r}
sum(is.na(hc$household_composition_one_person_household_measures_value))
```
```{r}
sum(is.na(hc$household_composition_all_categories_household_composition_measures_value))
```
### Predictors

```{r}
# join population density, IMD, and ethnicity to LSOA boundary
predictors <- lsoa %>%
  left_join(.,
            samhi_2011, 
            by = c("LSOA11CD"="lsoa11"))%>%
  left_join(.,
            pd_2011, 
            by = c("LSOA11CD"="geography_code"))%>%
  left_join(.,
            depriv_2011, 
            by = c("LSOA11CD"="codes"))%>%
  left_join(.,
            hc_2011, 
            by = c("LSOA11CD"="geography_code"))
```

```{r}
# join population density, IMD, and ethnicity to LSOA boundary
predictors <- samhi_2011 %>%
  left_join(.,
            pd_2011, 
            by = c("lsoa11"="geography_code"))%>%
  left_join(.,
            depriv_2011, 
            by = c("lsoa11"="codes"))%>%
  left_join(.,
            hc_2011, 
            by = c("lsoa11"="geography_code"))
```

```{r}
write.csv(df, file='./data.csv')
```

```{r}
# join population density, IMD, and ethnicity to LSOA boundary
join <- lsoa %>%
  left_join(.,
            samhi_2011, 
            by = c("LSOA11CD"="lsoa11"))%>%
  left_join(.,
            pd_2011, 
            by = c("LSOA11CD"="geography_code"))%>%
  left_join(.,
            depriv_2011, 
            by = c("LSOA11CD"="codes"))%>%
  left_join(.,
            hc_2011, 
            by = c("LSOA11CD"="geography_code"))
```

```{r}
df <- join%>%
  select(.,LSOA11CD, samhi_dec, area_population_density_density_number_of_persons_per_hectare_measures_value, unemployment_rate, annual_income, single_hc)%>%
  rename(pop_dens=area_population_density_density_number_of_persons_per_hectare_measures_value)%>%
  clean_names()
```

```{r}
Datatypelist <- df %>% 
  st_drop_geometry() %>%
  summarise_all(class) %>%
  pivot_longer(everything(), 
               names_to="All_variables", 
               values_to="Variable_class")
```

```{r}
h1 <- ggplot(df, aes(x=pop_dens)) +
  geom_histogram(color = "darkblue",
                 fill = "lightblue") +
  theme_bw()

h2 <- ggplot(df, aes(x=unemployment_rate)) +
  geom_histogram(color = "darkblue",
                 fill = "lightblue") +
  theme_bw()

h3 <- ggplot(df, aes(x=single_hc)) +
  geom_histogram(color = "darkblue",
                 fill = "lightblue") +
  theme_bw()

h4 <- ggplot(df, aes(x=annual_income)) +
  geom_histogram(color = "darkblue",
                 fill = "lightblue") +
  theme_bw()

plot_grid(h1,h2,h3,h4)
```

Most of the variables appear normally distributed, except for population density.

## Multiple Linear Regression

### Check for the Multicollinearity

```{r multicollinearity all}
# check their correlations are OK
# pearson correlation is only appropriate for interval or ratio data
# we are only concerned about multicollinearity between predictor variables
myvars <- df %>%
  dplyr::select(samhi_dec,pop_dens,unemployment_rate,single_hc,annual_income) %>%
  st_drop_geometry()

# get correlation matrix
cormat <- cor(myvars, use="complete.obs", method="pearson")

# significance test
sig1 <- corrplot::cor.mtest(myvars, conf.level = .95)

# create a correlogram
corrplot::corrplot(cormat, type = "lower",
                   method = "circle", 
                   order = "hclust", 
                   tl.cex = 0.7,
                   p.mat = sig1$p, sig.level = .05, 
                   col = viridis::viridis(100, option = "magma"),
                   diag = FALSE)
```

The size of the circle reflects the strength of the relationships as captured by the Pearson correlation coefficient. Crosses indicate statistically insignificant relationships at the 95% level of confidence. 

It looks like pop_dens is highly correlated with imd_score and less correlated with samhi_dec, so we will remove pop_dens as a predictor variable.

```{r multicollinearity selected}
myvars2 <- myvars %>%
  select(samhi_dec,unemployment_rate,pop_dens,single_hc)

cormat <- cor(myvars2, use="complete.obs", method="pearson")

# significance test
sig1 <- corrplot::cor.mtest(myvars2, conf.level = .95)

# create a correlogram
corrplot::corrplot(cormat, type="lower",
                   method = "circle", 
                   order = "original", 
                   tl.cex = 0.7,
                   p.mat = sig1$p, sig.level = .05, 
                   col = viridis::viridis(100, option = "plasma"),
                   diag = FALSE)
```

The remaining variables no longer exhibit strong multicollinearity, so I will refine my hypothesis as follows: 

* **Hypothesis:** Higher unemployment rate, population density and single person household lead to higher mental health illness

### Check for linear relationship between x and y

```{r linear relationship}
regression_data <- df %>%
  dplyr::select(lsoa11cd,
                samhi_dec,
                unemployment_rate,
                pop_dens,
                single_hc)

p1 <- ggplot(regression_data, aes(x=pop_dens, y=samhi_dec)) + 
  geom_point() +
  geom_smooth(method=lm) +
  theme_classic()

p2 <- ggplot(regression_data, aes(x=single_hc, y=samhi_dec)) + 
  geom_point() +
  geom_smooth(method=lm) +
  theme_classic()

p3 <- ggplot(regression_data, aes(x=unemployment_rate, y=samhi_dec)) + 
  geom_point() +
  geom_smooth(method=lm) +
  theme_classic()

plot_grid(p1, p2,p3)
```

There seems to be a slight positive relationship between all our predictor variables and the percentage of obesity in the population.

### Linear model
Now I will fit a linear model using the ordinary least squares method. 

```{r lm}
eq <- samhi_dec ~
  single_hc + pop_dens + unemployment_rate

ols_model <- lm(eq,
                data = regression_data)

# show the summary of those outputs
tidy(ols_model)
glance(ols_model)
summary(ols_model)
```

Result:
Adjusted R-squared = 32.6%

p-values:
unemployment= 6.599478e-194
single_hc= 2.590688e-230
pop_dens= 3.761510e-08

The results indicate that 32.6% of the variation in the mental health index can be explained by the deprivation score and average single household. The individual p-values for all predictor variables are significant at the 99.9% level of significance.

The higher rate of single household and unempolyment rate lead to higher SAMHI index (CMD cases) and the lower population density leads to higher SAMHI index.

### Check for normally distributed residuals

```{r normally distributed res}
shape_joined <- df %>%
  mutate(ols_model_res = residuals(ols_model))

ggplot(shape_joined, aes(x=ols_model_res)) +
  geom_histogram(color = "darkblue",
                 fill = "lightblue") +
  theme_bw()
```

The residuals appear to be normally distributed. 

### Check for homoscedasticity
Homoscedasticity refers to equal error variance for all x values. That is, the errors about the regression line do not vary with x. This can be verified using a residuals vs fits plot.

```{r res vs fits}
par(mfrow = c(2, 2))
plot(ols_model)
```

The residuals vs fitted values plot at the top left corner shows that when the fitted values are large, most of the residuals are negative. This may be a violation of the equal variance assumption, but otherwise, the other residuals show equal variance. 

The Normal Q-Q plot in the top right corner can be used to check if the residuals are normally distributed. If they are, they should follow a straight line, which is the case here. 

### Check for independent residuals

```{r map residuals}
tm_shape(shape_joined) +
  tm_polygons("ols_model_res")
```

The map shows that MSOAs with positive residuals seem to be neighbouring other MSOAs with positive residuals, while those with negative residuals also exhibit some clustering. 

To obtain a more quantitative measure of spatial autocorrelation, I will turn to Moran's I. 

#### Moran's I

```{r queen neighbours}
# calculate the centroids of MSOAs
centroids <- shape_joined %>%
  st_centroid() %>%
  st_geometry()

# the poly2nb function builds a neighbours list based on regions with contiguous boundaries, that is sharing one or more boundary point
# queen = TRUE means a single shared boundary point meets the contiguity condition
neighbours_list <- shape_joined %>%
  poly2nb(., queen=T)

summary(neighbours_list)

plot(neighbours_list, st_geometry(centroids), col="red")
plot(shape_joined$geometry, add = T)
```

932 out of 983 MSOAs are not connected to other regions, which could present errors later in our analysis. 

Thus, I will use k nearest neighbours with k set to 4 to generate the neighbours list. 

```{r knn}
# k nearest neighbours returns a matrix with the indices of points belonging to the set of the k nearest neighbours of each other
knn_msoa <- centroids %>%
  knearneigh(., k=4)

# convert the knn object returned by knearneigh into a neighbours list
knn_nb <- knn_msoa %>%
  knn2nb()

plot(knn_nb, st_geometry(centroids), col="blue")
plot(shape_joined$geometry, add = T)

```

Now run Moran's I test using row standardised spatial weights. 

```{r global moran}
# add spatial weights to neighbours list
lsoa_spatial_weights_list <- knn_nb %>%
  nb2listw(., style="W")

# run Moran's I test for spatial autocorrelation
global_moran <- shape_joined %>%
  pull(ols_model_res) %>%
  as.vector() %>%
  moran.test(., lsoa_spatial_weights_list) 

global_moran
```

The global Moran’s I statistic is 4.689294e-01 (1 = clustered, 0 = no pattern, -1 = dispersed) which shows that we have some distinctive clustering.

The p-value is less than 2.2e-16, indicating that the results are statistically significant at the 99.9% level of significance. We can reject the null hypothesis that the model residuals are randomly distributed among LSOAs.

The standard deviate (or Z-score) is positive (48.343), indicating that the spatial distribution of high values and/or low values of residuals is more spatially clustered than would be expected if underlying spatial processes were random.

## Spatial Regression Models

Now that we have established that spatial autocorrelation is present, there are two ways to deal with it, either by using a spatially lagged regression model or a spatial error model. 

### Lagrange Multiplier Test
I will use the lagrange multiplier test to decide whether to use the spatial lag or error model. 

```{r LMtests}
lm.LMtests(ols_model, lsoa_spatial_weights_list, 
           test = c("LMerr", "LMlag", "RLMerr", "RLMlag", "SARMA"))
```

The results show that the robust spatially lagged regression model (RLMlag = 0.042332) has a p-value that is much more significant than the robust spatial error model (RLMerr=568.62), so I will pick the spatially lagged regression model. 

### Spatially lagged regression model

```{r spatial lag model}
# Spatial simultaneous autoregressive lag model estimation
splag_model <- lagsarlm(eq, 
                        data = regression_data, 
                        lsoa_spatial_weights_list)

# what do the outputs show?
tidy(splag_model)
glance(splag_model)
summary(splag_model)
```

The spatially lagged regression model incorporates spatial dependence explicitly by adding a “spatially lagged” dependent variable, rho, on the right-hand side of the regression equation.

The results show that rho is statistically significant, and the estimate of rho (0.74) is larger than its standard error (0.02), so we can conclude that there is some spatial dependence which we should bear in mind when interpreting the results of our regression model.

In our scenario, this means that the obesity percentage in one MSOA may be associated with or influenced by the obesity percentage in the four nearest neighbouring MSOAs (as defined in our neighbours list).
 
To check if this is true, I will use Moran's I to identify spatial autocorrelation in the dependent variable, obesity percentage.

```{r moran I obesity}
global_moran_cmd <- shape_joined %>%
  pull(samhi_dec) %>%
  as.vector() %>%
  moran.test(., lsoa_spatial_weights_list) 

global_moran_cmd
```

The Moran's I statistic confirms that the spatial distribution of high values and/or low values of obesity percentage across MSOAs is spatially clustered.

```{r map spatial lag res}
# write out the residuals
shape_joined <- shape_joined %>%
  mutate(splag_model_res = residuals(splag_model))

tm_shape(shape_joined) + 
  tm_polygons(col = "splag_model_res") +  
  tm_compass(type = "arrow", position = c("right", "top") , size = 2) + 
  tm_scale_bar(breaks = c(0,1,2), text.size = 0.7, position =  c("right", "bottom")) + 
  tm_layout(bg.color = "white", legend.outside = TRUE)
```

```{r moran I residuals}
# check that the residuals from the spatially lagged model are now no longer exhibiting spatial autocorrelation
splag_moran <- moran.test(shape_joined$splag_model_res, 
                          msoa_spatial_weights_list)

splag_moran
```

The results of Moran’s I test for spatial autocorrelation show that the residuals of the spatially lagged regression model are no longer spatially autocorrelated, as the Moran I statistic is close to 0. However, this result is not statistically significant, as the p-value is large.

## Geographically Weighted Regression
Perhaps the spatial autocorrelation that we have observed for obesity percentages in London MSOAs is indicative of some local variation that the global OLS model has failed to capture. 

GWR explores how the relationship between a dependent variable (Y) and one or more independent variables (the Xs) might vary geographically.

```{r gwr bandwidth}
centroids2 <- st_coordinates(centroids)

shape_joined2 <- cbind(shape_joined, centroids2)

# find optimal kernel bandwidth
GWR_bandwidth <- gwr.sel(eq,
                         data = shape_joined2,
                         coords = cbind(shape_joined2$X,
                                        shape_joined2$Y),
                        # provide an adaptive bandwidth as opposed to a fixed bandwidth
                        adapt = TRUE)

GWR_bandwidth

```
The optimal bandwidth is about 0.0034 meaning 0.34% of all the total spatial units should be used for the local regression based on k-nearest neighbours. This is about 3 of the 983 MSOAs.


```{r fit gwr model}
# fit the gwr model based on adaptive bandwidth
gwr_abw <- gwr(eq,
               data = shape_joined2, 
               coords = cbind(shape_joined2$X, shape_joined2$Y), 
               adapt = GWR_bandwidth, 
               # matrix output
               hatmatrix = TRUE, 
               # standard error
               se.fit = TRUE)

# print the results of the model
gwr_abw

results <- as.data.frame(gwr_abw$SDF)
# names(results)
```

The coefficients for the weight of fat in the average food product range from a minimum value of -10.6 (1 gram increase in fat resulting in a drop in obesity percentage of 10.6) to +8.16 (1 gram increase in fat resulting in a increase in obesity percentage of 8.16). 

For half of the MSOAs in the dataset, as the weight of the average food product increases by 1 gram, the obesity percentage will increase between 0.012 and 0.067 points (the inter-quartile range between the 1st Qu and the 3rd Qu).

```{r save results}
# save localR2 and coefficients to original data frame
shape_joined2$abw_localR2 <- results$localR2

shape_joined2$coef_weight <- results$weight

shape_joined2$coef_fat <- results$fat

shape_joined2$coef_log_f_soft_drinks <- results$log_f_soft_drinks
```

### Map local R2

```{r map local r2}
# map local R2
legend_title = expression("Adaptive bandwidth: Local R2")

map_abgwr1 = tm_shape(shape_joined2) +
  tm_fill(col = "abw_localR2", title = legend_title, 
          palette = "Oranges", style = "cont") +
  tm_borders(col = "gray", lwd = .1) + 
  tm_compass(type = "arrow", position = c("right", "top") , size = 2) + 
  tm_scale_bar(breaks = c(0,1,2), text.size = 0.7, position =  c("right", "bottom")) +
  tm_layout(bg.color = "white", legend.outside = TRUE)

map_abgwr1
```

The local R-squared values range from 0.2 to 0.8, with several MSOAs near the center having higher R-squared values. 

### Map the coefficients

```{r map coef}
# weight
legend_title = expression("Weight of average food product (grams)")

map_abgwr2 = tm_shape(shape_joined2) +
  tm_fill(col = "coef_weight", title = legend_title, 
          palette = "RdBu", style = "cont") + 
  tm_borders(col = "gray", lwd = .1)  +
  tm_compass(type = "arrow", position = c("right", "top") , size = 2) +
  tm_scale_bar(breaks = c(0,1,2), text.size = 0.7, position =  c("left", "bottom")) + 
  tm_layout(bg.color = "white", legend.outside = TRUE)

map_abgwr2

# fat
legend_title = expression("Weight of fat in the average product (grams)")

map_abgwr3 = tm_shape(shape_joined2) +
  tm_fill(col = "coef_fat", title = legend_title, 
          palette = "RdBu", style = "cont") + 
  tm_borders(col = "gray", lwd = .1)  + 
  tm_compass(type = "arrow", position = c("right", "top") , size = 2) +
  tm_scale_bar(breaks = c(0,1,2), text.size = 0.7, position =  c("left", "bottom")) + 
  tm_layout(bg.color = "white", legend.outside = TRUE) 

map_abgwr3

# soft drinks
legend_title = expression("Log(fraction of soft drinks purchased)")

map_abgwr4 = tm_shape(shape_joined2) +
  tm_fill(col = "coef_log_f_soft_drinks", title = legend_title, 
          palette = "RdBu", style = "cont") + 
  tm_borders(col = "gray", lwd = .1)  + 
  tm_compass(type = "arrow", position = c("right", "top") , size = 2) +
  tm_scale_bar(breaks = c(0,1,2), text.size = 0.7, position =  c("left", "bottom")) + 
  tm_layout(bg.color = "white", legend.outside = TRUE) 

map_abgwr4
```

The coefficients for the weight of the average food product show that the relationship between this variable and obesity percentage is positive for most MSOAs, especially in some central areas towards the south of the river. 

Interestingly, on the outskirts of London, the relationship between weight of the average food product and obesity is negative (indicated in red on the map), which is unexpected. There could be some other factors at play that are unrelated to diets, perhaps related to lifestyle habits.

The coefficients for the weight of fat in the average product show that some MSOAs have negative coefficients, meaning that an increase in the weight of fat in the average product leads to a decrease in obesity percentage. 

The coefficients for the log transformed fraction of soft drinks purchased show that there is mostly a positive relationship between this variable and obesity percentage across MSOAs. 

### Assessing statistical significance
Roughly, if a coefficient estimate has an absolute value of t greater than 1.96 and the sample is sufficiently large, then it is statistically significant.

```{r t statistic weight}
# compute t statistic
shape_joined2$t_weight = results$weight / results$weight_se

# categorise t values
shape_joined2$t_weight_cat <- cut(shape_joined2$t_weight,
                     breaks = c(min(shape_joined2$t_weight), 
                              -1.96, 1.96, 
                              max(shape_joined2$t_weight)),
                     labels = c("sig","nonsig", "sig"))

# map statistically significant coefs
legend_title = expression("Weight of avg food product: significant")

map_sig_weight = tm_shape(shape_joined2) + 
  tm_fill(col = "t_weight_cat", title = legend_title, 
          legend.hist = TRUE, midpoint = NA, 
          textNA = "", colorNA = "white") +  
  tm_borders(col = "grey", lwd = .1)  + 
  tm_compass(type = "arrow", position = c("right", "top") , size = 2) + 
  tm_scale_bar(breaks = c(0,1,2), text.size = 0.7, position =  c("right", "bottom")) + 
  tm_layout(bg.color = "white", legend.outside = TRUE)

map_sig_weight
```

For slightly more than half of the MSOAs, the results for the weight of the average food product are statistically significant in explaining obesity percentages. 

```{r t statistic fat}
# compute t statistic
shape_joined2$t_fat = results$fat / results$fat_se

# categorise t values
shape_joined2$t_fat_cat <- cut(shape_joined2$t_fat,
                     breaks = c(min(shape_joined2$t_fat), 
                              -1.96, 1.96, 
                              max(shape_joined2$t_fat)),
                     labels = c("sig","nonsig", "sig"))

# map statistically significant coefs 
legend_title = expression("Weight of fat in avg food product: significant")

map_sig_fat = tm_shape(shape_joined2) + 
  tm_fill(col = "t_fat_cat", title = legend_title, 
          legend.hist = TRUE, midpoint = NA, 
          textNA = "", colorNA = "white") +  
  tm_borders(col = "grey", lwd = .1)  + 
  tm_compass(type = "arrow", position = c("right", "top") , size = 2) + 
  tm_scale_bar(breaks = c(0,1,2), text.size = 0.7, position =  c("right", "bottom")) + 
  tm_layout(bg.color = "white", legend.outside = TRUE)

map_sig_fat
```

This map shows that the weight of fat in the average food product is not statistically significant for most of the MSOAs, so we should take this into account when interpreting the results of this variable in the GWR. 

## Reflection
In conclusion, I have looked at three dietary factors and their relationship with obesity percentages, namely, the weight of the average food product, the weight of fat in the average food product, and the fraction of soft drinks purchased. 

I have used three different models to model the relationship between these factors and obesity, namely, the ordinary least squares multiple linear regression model, the spatially lagged regression model and finally, the geographically weighted regression model. 

In general, the results show that higher weights of the average food product and fat in the average food product are associated with higher obesity percentages, so policymakers can look into ways to encourage people to reduce these numbers to combat obesity.


```{r}
# plot population density
map_samhi <- tm_shape(df)+
  tm_fill(col="samhi_dec", 
          title = "London Common Mental Health index 2011",
          style = "cont",
          textNA = "No data",
          colorNA = "white", 
          palette = "RdBu")+
  tm_borders(col = "gray", lwd = .1) +
  tm_compass(type = "arrow", position = c("right", "top") , size = .5) +
  tm_scale_bar(breaks = c(0,1,2), text.size = 0.7, position =  c("left", "bottom")) +
  tm_layout(bg.color = "white", legend.outside = TRUE)
map_samhi
```

```{r}
# plot population density
map_pd <- tm_shape(df)+
  tm_fill(col="pop_dens", 
          title = "London Population Density 2011",
          breaks = c(0,200,400,450,500,550,600,650,700),
          style = "cont",
          textNA = "No data",
          colorNA = "white", 
          palette = "RdBu")+
  tm_borders(col = "gray", lwd = .1) +
  tm_compass(type = "arrow", position = c("right", "top") , size = .5) +
  tm_scale_bar(breaks = c(0,1,2), text.size = 0.7, position =  c("left", "bottom")) +
  tm_layout(bg.color = "white", legend.outside = TRUE)
map_pd
```

```{r}
# plot deprivation index (IMD)
map_imd <- tm_shape(df)+
  tm_fill(col="unemployment_rate", 
          title = "Unemployment rate 2011",
          style = "cont",
          textNA = "No data",
          colorNA = "white", 
          palette = "RdBu")+
  tm_borders(col = "gray", lwd = .1) +
  tm_compass(type = "arrow", position = c("right", "top") , size = .5) +
  tm_scale_bar(breaks = c(0,1,2), text.size = 0.7, position =  c("left", "bottom")) +
  tm_layout(bg.color = "white", legend.outside = TRUE)
map_imd
```

```{r}
# plot deprivation index (IMD)
map_imd <- tm_shape(df)+
  tm_fill(col="single_hc", 
          title = "Single Household Percentage 2011",
          style = "cont",
          textNA = "No data",
          colorNA = "white", 
          palette = "RdBu")+
  tm_borders(col = "gray", lwd = .1) +
  tm_compass(type = "arrow", position = c("right", "top") , size = .5) +
  tm_scale_bar(breaks = c(0,1,2), text.size = 0.7, position =  c("left", "bottom")) +
  tm_layout(bg.color = "white", legend.outside = TRUE)
map_imd
```